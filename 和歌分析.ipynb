{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "和歌分析.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCE6AxacFW4yTLxe4HaH7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afujii/class/blob/main/%E5%92%8C%E6%AD%8C%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEuB66S_ytsU"
      },
      "source": [
        "## 和歌の分析\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhe044FGydmP"
      },
      "source": [
        "以下のファイルを分析対象とする。このファイルは、縦書き一太郎から横書きUTF8コードテキストを生成し、成形したものである。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or51VqLdDp6q",
        "outputId": "f7e006d7-4129-4046-faf0-aafb12270349"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H31EU8UzyYBH",
        "outputId": "baadb85b-e7e6-4ad2-c477-07369f85249e"
      },
      "source": [
        "daiuta = {}\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/daiuta.txt') as f:\n",
        "  for line in lines:\n",
        "    l = line.split(\",\")\n",
        "    daiuta[l[0]] = l[1]\n",
        "data = list(daiuta.items())\n",
        "print(data[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('祝', '神代よりをしへのままのあととめて榮ひさしきしきしまの道\\n'), ('題不知', 'みな人は上に目がつく横にゆく葦間のかにのあはれなる世や\\n'), ('後陽成院五日百首', 'ちかひなほ世世にかはらで八嶋もる國つみ神は頼もしきかな\\n')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6cI-UvS3I5B"
      },
      "source": [
        "次に分析用の形態素解析環境を整える。Janome、Spacy、MeCabなどがある。以下では、MeCapの一般的な辞書をつかう例を示す。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyinnWEh13vg"
      },
      "source": [
        "!pip install mecab-python3\n",
        "!pip install unidic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV7pohGS2KPc"
      },
      "source": [
        "!python -m unidic download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xEVeIo-2lDo"
      },
      "source": [
        "MeCabを利用した「形容詞」「名詞」「動詞」による分かち書きの例を以下に示す。頻出単語を示す。古語辞書を利用する場合と語彙が異なる。その比較をColabの上で示すのは煩雑なので省略する。\n",
        "分かち書きした後、語彙の頻出50位までを示す。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzqFNtfY3Zvb",
        "outputId": "2664928a-d5fb-4a2f-bb16-662ea2569d4a"
      },
      "source": [
        "import MeCab\n",
        "tagger = MeCab.Tagger()\n",
        "\n",
        "# 歌ごとにparse\n",
        "words = {}\n",
        "for uta in data:\n",
        "  res = tagger.parse(uta[1])\n",
        "  tags = res.split('\\n')\n",
        "  for t in tags:\n",
        "    elements = t.split(',')[0].split('\\t')\n",
        "    if len(elements)>1 and \\\n",
        "       (elements[1]=='形容詞' or \\\n",
        "        elements[1]=='名詞' or \\\n",
        "        elements[1]=='動詞'):\n",
        "      if elements[0] not in words.keys():\n",
        "        words[elements[0]]=0\n",
        "      words[elements[0]] += 1\n",
        "stat = sorted(words.items(),key= lambda x : x[1],reverse = True)\n",
        "for i in stat[0:30]:\n",
        "  print(i[0]+\"\\t\\t\"+str(i[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "神\t\t29\n",
            "春\t\t29\n",
            "し\t\t28\n",
            "き\t\t26\n",
            "世\t\t24\n",
            "月\t\t20\n",
            "山\t\t19\n",
            "道\t\t18\n",
            "國\t\t15\n",
            "なき\t\t15\n",
            "ひ\t\t15\n",
            "花\t\t15\n",
            "神代\t\t14\n",
            "人\t\t13\n",
            "葉\t\t13\n",
            "千代\t\t13\n",
            "秋\t\t12\n",
            "心\t\t11\n",
            "年\t\t11\n",
            "いく\t\t11\n",
            "こと\t\t10\n",
            "見\t\t10\n",
            "色\t\t10\n",
            "世世\t\t9\n",
            "松\t\t9\n",
            "よろづ\t\t9\n",
            "ひかり\t\t9\n",
            "ぎ\t\t9\n",
            "こころ\t\t8\n",
            "露\t\t8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3hiR78E5KPC"
      },
      "source": [
        "以降、これまで利用した daiuta.txt ファイルを用いる。機械学習として、2つの分析を試みる。第１は、　word2vec による学習。第2はLSTMによる学習である。別なファイルで紹介する。\n"
      ]
    }
  ]
}